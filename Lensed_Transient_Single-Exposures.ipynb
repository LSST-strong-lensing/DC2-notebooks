{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8859a3a3-33d1-46f8-9a25-62811c9540bf",
   "metadata": {},
   "source": [
    "# DDF lensed transient single exposures access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43da65-537b-488b-9ce9-f3e35aec91ba",
   "metadata": {},
   "source": [
    "This repo shows how to access the catalog of lensed transients inserted in the DC2's deep drilling fields and how to pull single callibrated exposure images and light curves. So far only the first two year worth of simulation have been processed. If you find that there are more recent processings available that are not being used here, please feel free to submit an issue [here](https://github.com/LSST-strong-lensing/DC2-notebooks/issues).\n",
    "\n",
    "This notebook is largely based on [DP0 notebook tutorials](https://github.com/rubin-dp0/tutorial-notebooks), initially written by Melissa Graham. \n",
    "\n",
    "**Created:** 05-11-2022 by Rémy Joseph \\\n",
    "**Last reviewed:** 06-09-2022 by Rémy Joseph \\\n",
    "**Kernel used:** `desc-stack-weekly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0318896-811a-48ac-be99-c87873d4c0f3",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Lensed transients and their host and lensed galaxies were introduced in DC2 run 3.1i as part of the [Lens Sprinkler project](https://portal.lsstdesc.org/DESCPub/app/PB/show_project?pid=35) led by Bryce Klambach and Ji Won Park. Their work should be acknowledged in any published materials that makes use of this work.\n",
    "The Deep Drilling Fields (DDF) were injected with a sample of a few 1000s lensed quasars and supernovae. This notebook is intended to help anyone who might want to use this sample to run their own finding or analysis tools.\n",
    "\n",
    "This notebook makes use of the gen3 butler developped by the project. More information can be found in the [LSST science pipelines documentation](https://pipelines.lsst.io/getting-started/dc2-guide.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fefddc-27c9-460d-8033-23b5b256e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Generic python packages\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlalchemy \n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import astropy\n",
    "from astropy.time import Time\n",
    "\n",
    "# Set a standard figure size to use\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "# Some plotting tools\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.transforms import Affine2D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.daf.base as dafBase\n",
    "import lsst.afw.display as afwDisplay\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "from lsst.afw.image import MultibandExposure\n",
    "import lsst.geom as geom\n",
    "import lsst.sphgeom as sphgeom\n",
    "import lsst.afw.coord as afwCoord\n",
    "import lsst.geom as afwGeom\n",
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "\n",
    "# imports python's garbage collector\n",
    "import gc                            \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "import mpl_toolkits.axisartist.floating_axes as floating_axes\n",
    "from mpl_toolkits.axisartist.grid_finder import DictFormatter, MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec04e1c-c9b1-4c2c-ae7d-d3ee03aec5e5",
   "metadata": {},
   "source": [
    "The Butler is the object that enables us to retrieve, read and write data. To create the Butler, we need to provide it with a path to the data set, which is called a \"data repository\". Butler repositories have both a database component and a file-like storage component; the latter can can be remote (i.e., pointing to an S3 bucket) or local (i.e., pointing to a directory on the local file system), and it contains a configuration file (usually butler.yaml) that points to the right database.\n",
    "\n",
    "At the moment only the first 2 years-worth of observation of the DDF have calexp images available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd086ae2-ee89-49b8-a43b-96eb0e06e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the repo containing the Run3.1i DDF data:\n",
    "repo = '/global/cfs/cdirs/lsst/production/gen3/DC2/Run3.1i/repo'\n",
    "\n",
    "# These are the collections containing the Y1 processed visit images, etc..\n",
    "collections = ['u/descdm/sfp_ddf_visits_part_00',\n",
    "               'u/descdm/sfp_ddf_visits_part_01',\n",
    "              ]\n",
    "\n",
    "# Create a data butler and registry\n",
    "butler = dafButler.Butler(repo, collections=collections)\n",
    "registry = butler.registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89372380-1f0a-4935-ba4a-8508d6b2973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_time(ra, \n",
    "               dec, \n",
    "               butler=None, \n",
    "               time=None, \n",
    "               skymap=None, \n",
    "               regions=[{\"time\": [[Time('2022-01-01T03:21:12.552', \n",
    "                                         format='isot', \n",
    "                                         scale='utc'),\n",
    "                                   Time('2023-12-31T06:55:22.651', \n",
    "                                         format='isot', \n",
    "                                         scale='utc')]]}]):\n",
    "    \"\"\"\n",
    "    Returns True if a set of coordinates (including time) is in a given region.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ra, dec: float\n",
    "        Ra and Dec Coordinates.\n",
    "    butler: lsst.daf.persistence.Butler\n",
    "        servant providing access to a data repository\n",
    "    time: astropy.time\n",
    "        time of observation (event).\n",
    "    skymap: lsst.afw.skyMap.SkyMap [optional]\n",
    "        Pass in to avoid the Butler read.  Useful if you have lots of them.\n",
    "    regions: array\n",
    "        Array of dictionnaries containing available patches, tracts and time limits.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    is_in: bool\n",
    "        True if ‘(ra, dec)‘ is in ‘region‘\n",
    "    \"\"\"\n",
    "    radec = geom.SpherePoint(ra, dec, geom.degrees)\n",
    "    \n",
    "    for r in regions:\n",
    "        if time is not None:\n",
    "            if np.size(r[\"time\"]) > 0:\n",
    "                for span in r[\"time\"]:\n",
    "                    if (time < span[1]) and (time > span[0]):\n",
    "                        return True\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18260fdf-5250-42b0-a26b-9f81b0aaa7e2",
   "metadata": {},
   "source": [
    "# Load the lensed transient truth\n",
    "\n",
    "Here we load the catalogs for inserted lensed transients that were generated as part of the LensSprinkler project. These are the truth tables that give the positions of the simulated lensed transients as they were inserted. \n",
    "\n",
    "It is possible to overlay the patches that have been processed so far. Note that it takes a few seconds to build so by default that display is not produced, but if you set ‘show_patches‘ ti ‘True‘, the patches will appear on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38fa4f-99a0-4525-8bef-50c320344eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases and location for truth catalogs\n",
    "folder = '/global/cfs/cdirs/descssim/DC2/Run3.0i/truth_tables/'\n",
    "truth_sn = 'updated_lensed_sne_truth.db'\n",
    "truth_agn = 'updated_lensed_agn_truth.db'\n",
    "\n",
    "# Set to true to visualize the tract:4848, patches:35,36,42,43 area.\n",
    "show_patches = True\n",
    "\n",
    "try:\n",
    "    conn_sn = sqlite3.connect(folder+truth_sn)   \n",
    "    conn_agn = sqlite3.connect(folder+truth_agn)   \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "#Now in order to read in pandas dataframe we need to know table name\n",
    "cursor = conn_sn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "sn = pd.read_sql_query('SELECT * FROM lensed_sne', conn_sn)\n",
    "conn_sn.close()\n",
    "\n",
    "cursor = conn_agn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "agn = pd.read_sql_query('SELECT * FROM lensed_agn', conn_agn)\n",
    "conn_agn.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Positions of lensed transients', fontsize = 30)\n",
    "plt.plot(sn.ra, sn.dec, 'or', label = 'SN')\n",
    "plt.plot(agn.ra, agn.dec, 'ob', label = 'AGN')\n",
    "plt.xlabel('Ra', fontsize = 20)\n",
    "plt.ylabel('Dec', fontsize = 20)\n",
    "plt.legend(fontsize = 15, loc=\"upper right\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a3504-b6cb-45e7-afa2-3f3bec3879fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lens_radec(cat, \n",
    "                   butler=None, \n",
    "                   regions=[{\"time\": [[Time('2022-01-01T03:21:12.552', \n",
    "                                           format='isot', \n",
    "                                           scale='utc'),\n",
    "                                      Time('2023-12-31T06:55:22.651', \n",
    "                                           format='isot', \n",
    "                                           scale='utc')]]}], \n",
    "                   time=False, \n",
    "                   skymap=None):\n",
    "    \n",
    "    if skymap is None and butler is not None:\n",
    "        skymap = butler.get(\"skymap\")\n",
    "    inumber = -1\n",
    "    radec = []\n",
    "    lens_radec = []\n",
    "    for index, row in cat.iterrows():\n",
    "        if row.image_number == inumber+1:\n",
    "            radec.append([row.ra, row.dec])\n",
    "        else: \n",
    "            #assert len(radec) in [2,4], f\"there should be either 2 or 3 images in a lens system but {len(radec)} were found\"\n",
    "            lens_ra, lens_dec = np.mean(radec, axis=0)\n",
    "            # Only saves the lenses that are in the processed regions\n",
    "            if time == True:\n",
    "                t = Time(row.t0+row.t_delay, format='mjd')\n",
    "            else:\n",
    "                t = None\n",
    "            if regions is not None:\n",
    "                if is_in_time(lens_ra, lens_dec, butler, time=t, skymap=skymap, regions = regions):\n",
    "                    lens_radec.append({'coord': np.mean(radec, axis=0), 'image_pos':radec, 't0':t, 'n_images':inumber+1})\n",
    "            else:\n",
    "                lens_radec.append({'coord': np.mean(radec, axis=0), 'image_pos':radec, 't0':t, 'n_images':inumber+1})\n",
    "            radec = []\n",
    "            radec.append([row.ra, row.dec])\n",
    "            \n",
    "        inumber = row.image_number\n",
    "    return lens_radec\n",
    "\n",
    "agn_lenses = get_lens_radec(agn)\n",
    "sn_lenses = get_lens_radec(sn, time=True)\n",
    "\n",
    "print(f\"There are {len(agn_lenses)} AGNs in the DC2 3.1i DDF and {len(sn_lenses)} supernovae out of {len(get_lens_radec(sn))} are exploding during Y1-Y2.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70ee69-8c22-43d9-ab61-565a78c74415",
   "metadata": {},
   "source": [
    "To view all the information available about each image, in each catalog, uncomment the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04fda1-3b2e-46d1-831b-53a5d5a8d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sn.columns)\n",
    "#print(agn.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabc27f-d41e-4c58-8236-61b4093ceaf6",
   "metadata": {},
   "source": [
    "This catalog contains the positions for each image of a strongly lensed transient. This means that a quadrupely lensed supernova will have 4 entries in the catalog: one for each image. In the next box we produce the approximate coordinates of the lenses by averaging over the image coordinates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a9d0f-d5b9-487b-bba0-96dac3ccf241",
   "metadata": {},
   "source": [
    "## Querying for calexp data\n",
    "\n",
    "The database side of a data repository is called a registry. The registry contains entries for all data products, and organizes them by collection, dataset type, and data ID. Use the registry to investigate a repository by listing all collections. Specifying collections allow to browse nested collections.\n",
    "\n",
    "Arbitrary spatial queries are not supported at this time, such as the \"POINT() IN (REGION)\" example found in this Butler queries documentation. In other words, at this time it is only possible to do queries involving regions that are already \"in\" the data repository, either because they are HTM pixel regions or because they are tract/patch/visit/visit+detector regions.\n",
    "\n",
    "Thus, for this example we use the set of dimensions that correspond to different levels of the HTM (hierarchical triangular mesh) pixelization of the sky (HTM primer). The process is to transform a region or point into one or more HTM identifiers (HTM IDs), and then create a query using the HTM ID as the spatial data ID. The lsst.sphgeom library supports region objects and HTM pixelization in the LSST Science Pipelines.\n",
    "\n",
    "The following function is meant to query for data sets that include a desired coordinate and observation date.\n",
    "\n",
    "We need to provide precise spatial and temporal information stored in the registry, which are represented in Python by Timespan and Region objects, respectively. DimensionRecord objects that represent spatial or temporal concepts (a visit is both) have these objects attached to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d173c61-999e-4384-ad82-097c5e84a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_transient(registry, radec, timespan, myband = 'r', mesh_lvl=10, time_limit=None):\n",
    "    \"\"\" Query the registry for temporal and spatial traget.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    radec: `SkyCoord` object\n",
    "        the coordinates of the object to query\n",
    "\n",
    "    timespan: `dafButler.timespan` object\n",
    "        time span for the object.\n",
    "        \n",
    "    mesh_lvl(optional): int\n",
    "        the level at which one sky pixel is about five arcmin across.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the hierarchical triangular mesh (HTM) for the position to query. Initialize a sky pixelization.\n",
    "    pixelization = sphgeom.HtmPixelization(mesh_lvl)\n",
    "    # Find the HTM ID for a desired sky coordinate.\n",
    "    htm_id = pixelization.index(sphgeom.UnitVector3d(sphgeom.LonLat.fromDegrees(\n",
    "                            radec.ra.value, radec.dec.value)))\n",
    "    \n",
    "    # Query the datasets.\n",
    "    datasetRefs = registry.queryDatasets(\"calexp\", htm20=htm_id, \n",
    "                                     where=f\"visit.timespan OVERLAPS my_timespan AND band = myband\",\n",
    "                                     bind={\"my_timespan\": timespan, \"myband\": myband})\n",
    "    \n",
    "    return datasetRefs\n",
    "\n",
    "def remove_figure(fig):\n",
    "    \"\"\"Remove a figure to reduce memory footprint. \"\"\"\n",
    "    # get the axes and clear their images\n",
    "    for ax in fig.get_axes():\n",
    "        for im in ax.get_images():\n",
    "            im.remove()\n",
    "    fig.clf()      # clear the figure\n",
    "    plt.close(fig) # close the figure\n",
    "    gc.collect()   # call the garbage collector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b28415-8d23-4b89-b744-e05078e9e0a5",
   "metadata": {},
   "source": [
    "## Extracting patches for single exposures\n",
    "\n",
    "Now we have functions that can query the datasets for specific times and locations. Knowing the time and place where Supernovae explode in our simulated set, we can therefore extract the patches that correspond to a SN exploding and sort the patches to display the evolution of a SN in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c513fe-0263-4691-894a-6766fdef7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_time_sorted_patches(catalog, registry, band='r', cutout_extent=20, limit=10):\n",
    "    \"\"\" Display patches starting at the beginning of an explosion and sorts them according to their time stamp.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    catalog: list\n",
    "        catalog of lensed objects with reference location\n",
    "    registry: butler.registry\n",
    "        registry to query the dataset.\n",
    "    band: string\n",
    "        The optical band to display.\n",
    "    cutout_extent: int\n",
    "        The number of pixels-on-a-side to cut a patch out.\n",
    "    limit: int\n",
    "        Limits the number of images to display.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for row in catalog:\n",
    "    \n",
    "        # Get a timespan object for the temporal side of the query.\n",
    "        if row['t0'] is not None:\n",
    "            timespan = dafButler.Timespan(Time( row['t0'], format='mjd'), Time(row['t0']+10, format='mjd'))\n",
    "        else:\n",
    "            timespan = dafButler.Timespan(Time('2022-01-01T03:21:12.552', \n",
    "                                         format='isot', \n",
    "                                         scale='utc'),\n",
    "                                   Time('2023-12-31T06:55:22.651', \n",
    "                                         format='isot', \n",
    "                                         scale='utc'))\n",
    "        # Get the physical location for the query\n",
    "        radec = SkyCoord(ra=row['coord'][0] * u.deg, dec= row['coord'][1] * u.deg)\n",
    "\n",
    "        #Querying the registry for calexps at specific location and time interval (t0+10 days)\n",
    "        dataset_i = query_transient(registry, radec, timespan, myband='i')\n",
    "        dataset_g = query_transient(registry, radec, timespan, myband='g')\n",
    "        dataset_r = query_transient(registry, radec, timespan, myband='r')\n",
    "\n",
    "        # Let's visualize the dates at which observations were taken\n",
    "        dates_g = [ref.dataId.timespan.begin.mjd for ref in dataset_g.expanded()]\n",
    "        dates_r = [ref.dataId.timespan.begin.mjd for ref in dataset_r.expanded()]\n",
    "        dates_i = [ref.dataId.timespan.begin.mjd for ref in dataset_i.expanded()]\n",
    "\n",
    "        if len(list(dataset_r))>1:\n",
    "            plt.title(\"MJD of observations\")\n",
    "            plt.hist(dates_g, label = f'g {len(dates_g)} observations', alpha=0.2)\n",
    "            plt.hist(dates_r, label = f'r {len(dates_r)} observations', alpha=0.2)\n",
    "            plt.hist(dates_i, label = f'i {len(dates_i)} observations', alpha=0.2)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        # So far, we restrin display to i-band only.\n",
    "        dates = dates_i\n",
    "        args = np.argsort(dates)\n",
    "        dates = np.array(dates)[args]\n",
    "\n",
    "        mjd_arr = []\n",
    "        calexp_arr = []\n",
    "        flux_arr = []\n",
    "        for i, ref in enumerate(tqdm(np.array(list(dataset_i))[args][:limit])):\n",
    "            transient_pos = row['image_pos']\n",
    "\n",
    "            # extract individual exposure with the butler.\n",
    "            calexp = butler.get('calexp', dataId=ref.dataId)\n",
    "\n",
    "            wcs = calexp.wcs\n",
    "\n",
    "            # Get the pixel position for the lensed images\n",
    "            point = geom.SpherePoint(row['coord'][0], row['coord'][1], geom.degrees)\n",
    "            xy = geom.PointI(wcs.skyToPixel(point))\n",
    "\n",
    "            if xy[0]<4072-cutout_extent and xy[1]<4000-cutout_extent and xy[0]>cutout_extent and xy[1]>cutout_extent:\n",
    "\n",
    "                bbox = afwGeom.Box2I()\n",
    "                bbox.include(afwGeom.Point2I(xy.x - cutout_extent,\n",
    "                                             xy.y - cutout_extent))\n",
    "                bbox.include(afwGeom.Point2I(xy.x + cutout_extent,\n",
    "                                             xy.y + cutout_extent))\n",
    "                x, y = [], []\n",
    "                for pos in transient_pos:\n",
    "                    pos = geom.SpherePoint(pos[0], pos[1], geom.degrees)\n",
    "\n",
    "                    xp, yp = wcs.skyToPixel(pos)\n",
    "                    x.append(xp-bbox.getMinX())\n",
    "                    y.append(yp-bbox.getMinY())\n",
    "\n",
    "                mat = np.eye(3)\n",
    "                mat[:2,:2] = wcs.getCdMatrix()\n",
    "                transform = Affine2D(mat)\n",
    "\n",
    "                image = calexp[bbox]\n",
    "                \n",
    "                \n",
    "                mjd_arr.append(dates[i])\n",
    "\n",
    "                fig = plt.figure()\n",
    "                arr = image.maskedImage.image.array#[xy.x-50:xy.x+50, xy.y-50:xy.y+50]\n",
    "                flux_arr.append(np.sum(arr))\n",
    "\n",
    "                plot_extents = 0, bbox.width, 0, bbox.height\n",
    "                helper = floating_axes.GridHelperCurveLinear(\n",
    "                    transform, plot_extents, \n",
    "                    tick_formatter1=DictFormatter({}),\n",
    "                    tick_formatter2=DictFormatter({}),\n",
    "                    grid_locator1=MaxNLocator(nbins=1),\n",
    "                    grid_locator2=MaxNLocator(nbins=1),\n",
    "                )\n",
    "                ax = floating_axes.FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "                ax.imshow(arr, transform=transform+ax.transData, interpolation = 'nearest', cmap='gist_stern')\n",
    "                ax.plot(x, y, 'ok', markersize=5, transform=transform+ax.transData)\n",
    "                ax.set_title(f\"Ra: {str(row['coord'][0])[:10]} Dec: {str(row['coord'][1])[:10]} MJD: {str(dates[i])[:10]} band: {ref.dataId['band']}\")\n",
    "                #ax.scatter(\n",
    "                #    xy.x - bbox.minX, \n",
    "                #    xy.y - bbox.minY, \n",
    "                #    c='r', marker='+', transform=transform+ax.transData\n",
    "                #)\n",
    "\n",
    "                fig.add_subplot(ax)\n",
    "                plt.show()\n",
    "\n",
    "                # clean up memory\n",
    "                remove_figure(fig)\n",
    "        if len(flux_arr)>1:\n",
    "            plt.title(\"light curve\", fontsize=45)\n",
    "            plt.plot(np.array(mjd_arr), np.array(flux_arr), 'o')\n",
    "            plt.xlabel(\"MJD\", fontsize=25)\n",
    "            plt.ylabel(\"flux\", fontsize=25)\n",
    "            plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e9117-30ed-4850-95aa-e33536029651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_time_sorted_patches(sn_lenses, registry, cutout_extent=20, limit = 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435a749-8466-4bfa-9ba5-da2f8420fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_time_sorted_patches(agn_lenses, registry, cutout_extent=20, limit = 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack-weekly",
   "language": "python",
   "name": "desc-stack-weekly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
